[
{
	"uri": "/es/",
	"title": "OptimizaciÃ³n de costos con servicios basados en AWS Graviton2",
	"tags": [],
	"description": "",
	"content": "Los procesadores AWS Graviton creados por Amazon Web Services utilizan nÃºcleos Arm Neoverse de 64 bits para ofrecer a nuestros clientes el mejor precio y rendimiento para sus cargas de trabajo en la nube que se ejecutan en Amazon EC2. Amazon EC2 proporciona el portafolio mÃ¡s amplio de mÃ¡quinas virtuales, mismas que funcionan tambiÃ©n con procesadores Intel y AMD de Ãºltima generaciÃ³n. Los procesadores AWS Graviton agregan una opciÃ³n mÃ¡s para ayudar a nuestros clientes a optimizar el rendimiento y el costo de sus cargas de trabajo.\nLos procesadores Graviton2 dan un gran salto en rendimiento comparados a la primera generaciÃ³n de estos mismos. Estos procesadores son encontrados en las familias de instancias EC2 T4g, M6g y R6g, ademÃ¡s de sus variantes con almacenamiento local SSD NVMe.\nEstos procesadores proveen hasta 40% de mejora en relaciÃ³n precio/rendimiento comparadas a generaciones actuales de instancias basadas en procesadores x84 para una amplia variedad de cargas de trabajo, incluyendo servidores de aplicaciones, microservicios, cÃ³mputo de alto rendimiento, diseÃ±o electrÃ³nico, videojuegos, bases de datos de cÃ³digo abierto y cachÃ©s en memoria.\nEstos procesadores Graviton2 de AWS proveen mejoras significativas para codificaciÃ³n de video, aceleraciÃ³n de hardware para compresiÃ³n y soportan inferencia para machine learning. Entregan 7 veces mÃ¡s rendimiento, 4 veces mÃ¡s nÃºcleos de cÃ³mputo, 5 veces mÃ¡s memoria y cachÃ©s 2 veces mÃ¡s grandes.\n"
},
{
	"uri": "/es/amazoncontainers/creatingpipeline.html",
	"title": "Crear el pipeline de construcciÃ³n del contenedor",
	"tags": [],
	"description": "",
	"content": "Comenzaremos creando un pipeline para construir imagenes de contenedor soportadas por mÃºltiples arquitecturas. El crear imagenes tanto para arquitecturas x86 como para arm64 nos permitirÃ¡n explorar el soporte nativo de los servicios de AWS para multi-arquitectura y nos permitirÃ¡ movernos a la opciÃ³n mÃ¡s Ã³ptima para nuestra carga de trabajo.\nEl stack de CDJ que implementarÃ¡s crearÃ¡ un repositorio de cÃ³difo para la aplicaciÃ³n hecha en NodeJS y dos pasos de construcciÃ³n para crear las imagenes de contenedor para arquitecturas x86 como para arm64.\n Inicia revisando el contenido del stack de CDK en el archivo graviton-labs/graviton2/cs_graviton/pipeline_graviton2.py para ambas arquitecturas.  Para construir imagenes multi-arquitectura no estamos utilizando ninguna capa de emulaciÃ³n. Utilizamos instancias de construcciÃ³n x86 y tambiÃ©n arm64 para asegurarnos que la construcciÃ³n sea nativa.\n ConstrucciÃ³n del contenedor en arquitectura x86 :\n docker_build_x86 = codebuild.PipelineProject( scope=self, id=f\u0026quot;DockerBuild_x86\u0026quot;, environment=dict( build_image=codebuild.LinuxBuildImage.AMAZON_LINUX_2_3, privileged=True), environment_variables={ 'REPO_ECR': codebuild.BuildEnvironmentVariable( value=container_repository.repository_uri), }, build_spec=buildspec_x86 ) ConstrucciÃ³n del contenedor en arquitectura arm64 :\n docker_build_arm64 = codebuild.PipelineProject( scope=self, id=f\u0026quot;DockerBuild_ARM64\u0026quot;, environment=dict( build_image=codebuild.LinuxBuildImage.AMAZON_LINUX_2_ARM, privileged=True), environment_variables={ 'REPO_ECR': codebuild.BuildEnvironmentVariable( value=container_repository.repository_uri), }, build_spec=buildspec_arm64 ) DespuÃ©s de construir las imagenes de contenedor vamos a subirlas (push) a un repositorio de imagenes localizado en Amazon ECR con tags que siguen el patron \u0026lt;COMMIT_HASH\u0026gt;: .\nEn este punto tu puedes jalar (pull) estas imagenes refiriÃ©ndote al tag especÃ­fico por arquitectura.\nSimplificaremos este proceso creando un manifest de docker multi-arquitectura y subiÃ©ndolo al repositorio localizado en ECR.\n La construcciÃ³n de principio a fin de la imagen de contenedor estÃ¡ descrita en la imagen siguiente:\nInicializa la implementaciÃ³n del pipeline al ejecutar este comando:  cdk deploy GravitonID-pipeline Una vez que la construcciÃ³n multi-arquitectura sea implementada, puedes proceder al siguiente paso en el que construiremos versiones de contenedores para x86 y arm64 de nuestra aplicaicÃ³n hecha en NodeJS.  "
},
{
	"uri": "/es/amazonrds/01_snapshot/creatingcluster8.html",
	"title": "Crear la instancia de RDS MySQL",
	"tags": [],
	"description": "",
	"content": "Empieza revisando los contenidos de stack de definicion de RDS MySQL 8 CDK. El archivo estÃ¡ en la siguiente ruta: graviton2_labs/rds_graviton/rds_mysql_8.py\n db_mysql8 = rds.DatabaseInstance(self, \u0026quot;MySQL8\u0026quot;, engine=rds.DatabaseInstanceEngine.mysql( version=rds.MysqlEngineVersion.VER_8_0_21 ), instance_type=ec2.InstanceType(\u0026quot;m5.4xlarge\u0026quot;), vpc=vpc, multi_az=False, publicly_accessible=True, allocated_storage=100, storage_type=rds.StorageType.IO1, iops=5000, cloudwatch_logs_exports=[\u0026quot;error\u0026quot;, \u0026quot;general\u0026quot;, \u0026quot;slowquery\u0026quot;], deletion_protection=False, enable_performance_insights=True, delete_automated_backups=True, backup_retention=core.Duration.days(1), parameter_group=rds.ParameterGroup.from_parameter_group_name( self, \u0026quot;para-group-mysql\u0026quot;, parameter_group_name=\u0026quot;default.mysql8.0\u0026quot; ) )  AWS Cloud Development Kit (CDK) simplifica la creaciÃ³n de servicios en AWS como por ejemplo crear instancias de Amazon RDS. El fragmento de cÃ³digo escrito en Python de arriba te permite crear una instancia de RDS MySQL 8 con 100GB y un volumen Amazon EBS de tipo IO1 en una Ãºnica zona de disponibilidad (single-AZ). Esta instancia es de tipo m5.4xlarge y sÃ³lo podrÃ¡s acceder a ella desde tu ambiente de Cloud9 environment a travÃ©s de su IP pÃºblica. La instancia RDS creada utilizando CDK tambiÃ©n tendrÃ¡ una politica de respaldos simple, generaciÃ³n de logs y la opciÃ³n de Performance Insights activados.\n Inicia la instancia RDS MySQL 8:  cdk deploy GravitonID-rds-8 Antes de conectarte a la instancia de MySQL necesitas agregar el usuario y contraseÃ±a a las variables de ambiente en tu sessiÃ³n de Cloud9.  CREDS=$(aws secretsmanager get-secret-value --secret-id `aws cloudformation describe-stacks --stack-name GravitonID-rds-8 --query \u0026#34;Stacks[0].Outputs[0].OutputValue\u0026#34; --output text` | jq -r \u0026#39;.SecretString\u0026#39;) export DBUSER=\u0026#34;`echo $CREDS| jq -r \u0026#39;.username\u0026#39;`\u0026#34; export DBPASS=\u0026#34;`echo $CREDS| jq -r \u0026#39;.password\u0026#39;`\u0026#34; export DBHOST=\u0026#34;`echo $CREDS| jq -r \u0026#39;.host\u0026#39;`\u0026#34; export DBPORT=\u0026#34;`echo $CREDS| jq -r \u0026#39;.port\u0026#39;`\u0026#34; echo $DBUSER echo $DBPASS echo $DBHOST echo $DBPORT Si las variables de ambiente se configuraron correctamente en el resultado de la ejecuciÃ³n anterior podras ver tu usuario, password, host y base de datos.  Avanza al siguiente capitulo \u0026ldquo;Importar Datos de prueba a MySQL\u0026rdquo;.\n"
},
{
	"uri": "/es/amazonrds/02_upgrade/creatingcluster5.html",
	"title": "Crear la instancia de RDS MySQL",
	"tags": [],
	"description": "",
	"content": "Revisa los contenidos de la definiciÃ³n del task en RDS MySQL 5, encontraras el archivo en labs/rds_graviton/rds_mysql_5.py\n db_mysql5 = rds.DatabaseInstance(self, \u0026quot;MySQL5\u0026quot;, engine=rds.DatabaseInstanceEngine.mysql( version=rds.MysqlEngineVersion.VER_5_7_31 ), instance_type=ec2.InstanceType(\u0026quot;m5.4xlarge\u0026quot;), vpc=vpc, multi_az=False, publicly_accessible=True, allocated_storage=100, storage_type=rds.StorageType.GP2, cloudwatch_logs_exports=[\u0026quot;audit\u0026quot;, \u0026quot;error\u0026quot;, \u0026quot;general\u0026quot;, \u0026quot;slowquery\u0026quot;], deletion_protection=False, enable_performance_insights=True, delete_automated_backups=True, backup_retention=core.Duration.days(1), parameter_group=rds.ParameterGroup.from_parameter_group_name( self, \u0026quot;para-group-mysql\u0026quot;, parameter_group_name=\u0026quot;default.mysql5.7\u0026quot; ) )  AWS Cloud Development Kit (CDK) simplifica la creaciÃ³n de servicios en AWS como por ejemplo crear instancias de Amazon RDS. El fragmento de cÃ³digo escrito en Python de arriba te permite crear una instancia de RDS MySQL 5 con 100GB y un volumen Amazon EBS de tipo GP2 en una Ãºnica zona de disponibilidad (single-AZ). Esta instancia es de tipo m5.4xlarge y sÃ³lo podrÃ¡s acceder a ella desde tu ambiente de Cloud9 environment a travÃ©s de su IP pÃºblica. La instancia RDS creada utilizando CDK tambiÃ©n tendrÃ¡ una politica de respaldos simple, generaciÃ³n de logs y la opciÃ³n de Performance Insights activados.\n Inicia la instancia RDS MySQL 5:  cdk deploy GravitonID-rds-5 Antes de conectarte a la instancia de MySQL necesitas agregar el usuario y contraseÃ±a a las variables de ambiente en tu sessiÃ³n de Cloud9.  CREDS=$(aws secretsmanager get-secret-value --secret-id `aws cloudformation describe-stacks --stack-name GravitonID-rds-5 --query \u0026#34;Stacks[0].Outputs[0].OutputValue\u0026#34; --output text` | jq -r \u0026#39;.SecretString\u0026#39;) export DBID=$(aws cloudformation describe-stacks --stack-name GravitonID-rds-5 --query \u0026#34;Stacks[0].Outputs[1].OutputValue\u0026#34; --output text) export DBUSER=\u0026#34;`echo $CREDS| jq -r \u0026#39;.username\u0026#39;`\u0026#34; export DBPASS=\u0026#34;`echo $CREDS| jq -r \u0026#39;.password\u0026#39;`\u0026#34; export DBHOST=\u0026#34;`echo $CREDS| jq -r \u0026#39;.host\u0026#39;`\u0026#34; export DBPORT=\u0026#34;`echo $CREDS| jq -r \u0026#39;.port\u0026#39;`\u0026#34; echo $DBUSER echo $DBPASS echo $DBHOST echo $DBPORT echo $DBID Si las variables de ambiente se configuraron correctamente en el resultado de la ejecuciÃ³n anterior podras ver tu usuario, password, host y base de datos.  Avanza al siguiente capitulo \u0026ldquo;Importar Datos de prueba a MySQL\u0026rdquo;.\n"
},
{
	"uri": "/es/gettingstarted.html",
	"title": "IntroducciÃ³n",
	"tags": [],
	"description": "",
	"content": "Estos primeros pasos se enfocan en configurar todos los prerequisitos para el laboratorio de Graviton 2. Con este proposito utilizaremos los siguientes servicios de AWS:\n Cloud9 IDE (Integrated Development Environment) AWS CDK (Cloud Development Kit)  Con AWS CDK principalmente configuraremos infraestructura estatica y algunos otros prerequisitos.\nSet up a Cloud9 IDE  En la consola de AWS, ve al servicio de Cloud9 y selecciona la opciÃ³n Create environment. Nombra tu nuevo IDE como Graviton2IDE y da click Next Step.\nEn la siguiente ventana selecciona la opciÃ³n \u0026ldquo;Other instance type\u0026rdquo; and elige el tipo de instancia m5.xlarge. DA click Next step.\nEn la pagina final, da click en Create environment. Asegurate de dejar los valores predefinidos en la secciÃ³n de configuraciÃ³n de conectividad.  Una vez que el ambiente sea construido y este activo serÃ¡s automaticamente redireccionado al IDE. Toma unos minutos para explorar la interfaz. Podras cambiar el esquema de colores si lo deseas (AWS Cloud9 menu -\u0026gt; Preferences -\u0026gt; Themes).\nAhora vamos a actualizar Cloud9 para poder ejecutar los laboratorios desde tu IDE.\n  Crea un nuevo rol para tu ambiente de Cloud9 dando click aquÃ­ link.\n  Confirma que el servicio de AWS EC2 esta seleccionado y da click en Next: Permissions.\n  Revisa que el permiso AdministratorAccess esta seleccionado y da click en Next: Tags.\n  Deja los valores predeterminados y da click en Next: Review, revisa que los parametros sean correctos.\n  Nombra tu rol como Cloud9-Admin-Role y da click en Create role.\n  Una vez que tu nuevo rol es creado ve al servicio de EC2, busca tu instancia de Cloud9, y asigna el rol a esta instancia (Actions -\u0026gt; Security -\u0026gt; Modify IAM role).\n  Regresa al servicio de Cloud9 y en el menÃº Preferences y bajo la pestaÃ±a de \u0026lsquo;AWS Credentials\u0026rsquo; deshabilita la opciÃ³n AWS managed temporary credentials.\n  Avanza al siguiente paso del laboratorio \u0026ldquo;Prerequisitos\u0026rdquo;.  "
},
{
	"uri": "/es/amazonemr/creatingcluster.html",
	"title": "Creando un Cluster de Amazon EMR con instancias Graviton2",
	"tags": [],
	"description": "",
	"content": " Crea el bucket de s3 para los jobs de EMR  cd ~/environment/graviton2-labs source scripts/create_emr_buckets.sh Ejecuta el siguiente comando para crear el clÃºster de EMR en tu VPC default  export EMR_CLUSTER_ID=$(aws emr create-cluster --name test-emr-cluster --use-default-roles --release-label emr-6.1.0 --instance-count 3 --instance-type m6g.xlarge --applications Name=JupyterHub Name=Spark --ec2-attributes KeyName=graviton2key | jq -r \u0026#39;.ClusterId\u0026#39;); echo \u0026#34;Your cluster ID is = $EMR_CLUSTER_ID\u0026#34; Autoriza conexiÃ³n ssh desde tu instancia de Cloud9  export C9_PRIVATEIP=$(curl -s 169.254.169.254/latest/dynamic/instance-identity/document | jq -r \u0026#39;.privateIp\u0026#39;) export EMR_MASTER_SG=$(aws emr describe-cluster --cluster-id $EMR_CLUSTER_ID | jq -r \u0026#39;.Cluster | .Ec2InstanceAttributes | .EmrManagedMasterSecurityGroup\u0026#39;) export EMR_MASTER_IP=$(aws emr describe-cluster --cluster-id $EMR_CLUSTER_ID | jq -r \u0026#39;.Cluster | .MasterPublicDnsName\u0026#39;) aws ec2 authorize-security-group-ingress --group-id $EMR_MASTER_SG --protocol tcp --port 22 --cidr $C9_PRIVATEIP/32 Copia el job de ETL en Spark al nodo maestro de EMR  scp scripts/etl-spark.py hadoop@$EMR_MASTER_IP:~/ ConÃ©ctate al nodo maestro de EMR y ejecuta el job de Spark  ssh hadoop@$EMR_MASTER_IP \u0026#34;spark-submit etl-spark.py s3://\u0026#39;$emr_s3_name\u0026#39;/input/ s3://\u0026#39;$emr_s3_name\u0026#39;/output/spark\u0026#34; Cuando el job de Spark sea inicializado via lÃ­nea de comando, logs serÃ¡n mostrados en la consola.\nEspera algunos minutos y navega a la consola de S3 para revisar la carpeta \u0026ldquo;output/spark\u0026rdquo; y ver los resultados  "
},
{
	"uri": "/es/amazoncontainers/multiarchitecture.html",
	"title": "ConstrucciÃ³n multi-arquitectura de la aplicaciÃ³n",
	"tags": [],
	"description": "",
	"content": " Antes de iniciar este laboratorio, por favor asegÃºrate de trabajar en la carpeta graviton2-labs. Si no estas ahÃ­, cÃ¡mbiate a esa carpeta ejecutando el siguiente comando en tu terminal:  cd ~/environment/graviton2-labs/ Clona un repositorio vacÃ­o de CodeCommit ejecutando:  git clone `aws cloudformation describe-stacks --stack-name GravitonID-pipeline --query \u0026#34;Stacks[0].Outputs[0].OutputValue\u0026#34; --output text` Copia los archivos de especificaciÃ³n de code build y el cÃ³digo fuente de la aplicaciÃ³n hecha en NodeJS hacia el nuevo repositorio de CodeCommit.  cp -r graviton2/cs_graviton/app/* graviton2-pipeline-lab/ Ejecuta los comandos siguientes para hacer commit y subir los cambios al repositorio de CodeCommit.  cd graviton2-pipeline-lab git add . git commit -m \u0026#34;First commit Node.js sample application.\u0026#34; git push Esto inicializarÃ¡\n la creaciÃ³n de la imagen de docker tanto para arquitectura x86 como para arm64 la creaciÃ³n del manifest multi-arquitecturade las imagenes de docker la carga de las imagenes de docker y el manifes al repositorio en Amazon ECR.   Monitorea los pasos del pipeline en CodePipeline utilizando la consola de AWS. Puedes ir directo a esta vista dando clic en la siguiente liga: https://console.aws.amazon.com/codesuite/codepipeline/pipelines/graviton2-pipeline-lab/view?region=us-east-1\n  Cuando todos los pasos del pipeline en CodePipeline hayan sido marcados como exitosos, ejecuta los siguientes comandos para configurar las variables de ambiente:\n  export ECR_REPO_URI=$(aws ecr describe-repositories --repository-name graviton2-pipeline-lab | jq -r \u0026#39;.repositories[0].repositoryUri\u0026#39;) export MULTI_IMAGE_TAG=$(aws ecr describe-images --repository-name graviton2-pipeline-lab --query \u0026#39;sort_by(imageDetails,\u0026amp; imagePushedAt)[-1].imageTags[0]\u0026#39; | jq -r .) export CONTAINER_URI=$ECR_REPO_URI:$MULTI_IMAGE_TAG echo $ECR_REPO_URI echo $MULTI_IMAGE_TAG echo $CONTAINER_URI aws ssm put-parameter --name \u0026#34;graviton_lab_container_uri\u0026#34; --value $CONTAINER_URI --type String --overwrite "
},
{
	"uri": "/es/amazonrds/01_snapshot/loadingdata.html",
	"title": "Importar Datos de prueba a MySQL",
	"tags": [],
	"description": "",
	"content": " Antes de iniciar este laboratorio, asegurate de estar en el directorio graviton2-labs. Si noe estas ahÃ­ ejecuta este comando en la terminal de Cloud9:  cd ~/environment/graviton2-labs/ Clona la base de datos de ejemplo de MySQL.\ngit clone https://github.com/datacharmer/test_db.git cd test_db Al terminar, conectate a tu instancia de MySQL ejecutando el siguiente comando:  mysql -h $DBHOST -P $DBPORT -u$DBUSER -p$DBPASS Si experimentas problemas en la conneciÃ³n debido a la falta de las variables de ambiente ejecuta el siguiente cÃ³digo para configurar las credenciales.\nCREDS=$(aws secretsmanager get-secret-value --secret-id `aws cloudformation describe-stacks --stack-name GravitonID-rds-8 --query \u0026#34;Stacks[0].Outputs[0].OutputValue\u0026#34; --output text` | jq -r \u0026#39;.SecretString\u0026#39;) export DBUSER=\u0026#34;`echo $CREDS| jq -r \u0026#39;.username\u0026#39;`\u0026#34; export DBPASS=\u0026#34;`echo $CREDS| jq -r \u0026#39;.password\u0026#39;`\u0026#34; export DBHOST=\u0026#34;`echo $CREDS| jq -r \u0026#39;.host\u0026#39;`\u0026#34; export DBPORT=\u0026#34;`echo $CREDS| jq -r \u0026#39;.port\u0026#39;`\u0026#34; echo $DBUSER echo $DBPASS echo $DBHOST echo $DBPORT Una vez conectado a tu instancia de MySQL carga una muestra de datos a tu instancia RDS. Para cargar datos ejecuta este comando desde el cliente de MySQL.  source employees.sql El motor comenzarÃ¡ a cargar los datos y verÃ¡s una salida similar a esta:\nQuery OK, 7671 rows affected (0.05 sec) Records: 7671 Duplicates: 0 Warnings: 0 +---------------------+ | data_load_time_diff | +---------------------+ | 00:00:33 | +---------------------+ 1 row in set (0.00 sec) mysql\u0026gt; Verifica que la tabla de empleados sea correcta ejecutando el checksum:  use employees; checksum table employees; El resultado serÃ¡ una tabla similar a la de abajo. Escribe los valores originales en un archivo para poder compararlos mÃ¡s tarde.\n+---------------------+-----------+ | Table | Checksum | +---------------------+-----------+ | employees.employees | 610052939 | +---------------------+-----------+ 1 row in set (0.24 sec) Sal del cliente de MySQL y crea un snapshot de la base de datos con el siguiente comando:  cd ~/environment/graviton2-labs/ ~/environment/graviton2-labs/scripts/rds-snapshot.sh Este script te regresarÃ¡ un snapshot id aleatorio\nMonitorea tu snapshot hasta que este listo usando la consola de AWS o ejecutando el siguiente cÃ³digo:  aws rds describe-db-snapshots --db-snapshot-identifier `aws ssm get-parameter --name \u0026#34;graviton_rds_lab_snapshot\u0026#34; | jq -r .Parameter.Value` | jq -r .DBSnapshots[0].Status Cuando el estado de tu snapshot cambie a \u0026ldquo;available\u0026rdquo; estarÃ¡s listo para continuar con el siguiente capitulo.  "
},
{
	"uri": "/es/amazonrds/02_upgrade/loadingdata.html",
	"title": "Importar Datos de prueba a MySQL",
	"tags": [],
	"description": "",
	"content": " Antes de iniciar este laboratorio, asegurate de estar en el directorio graviton2-labs. Si noe estas ahÃ­ ejecuta este comando en la terminal de Cloud9:  cd ~/environment/graviton2-labs/ Clona la base de datos de ejemplo de MySQL.\ngit clone https://github.com/datacharmer/test_db.git cd test_db Al terminar, conectate a tu instancia de MySQL ejecutando el siguiente comando:  mysql -h $DBHOST -P $DBPORT -u$DBUSER -p$DBPASS Si experimentas problemas en la conneciÃ³n debido a la falta de las variables de ambiente ejecuta el siguiente cÃ³digo para configurar las credenciales.\nCREDS=$(aws secretsmanager get-secret-value --secret-id `aws cloudformation describe-stacks --stack-name GravitonID-rds-5 --query \u0026#34;Stacks[0].Outputs[0].OutputValue\u0026#34; --output text` | jq -r \u0026#39;.SecretString\u0026#39;) export DBUSER=\u0026#34;`echo $CREDS| jq -r \u0026#39;.username\u0026#39;`\u0026#34; export DBPASS=\u0026#34;`echo $CREDS| jq -r \u0026#39;.password\u0026#39;`\u0026#34; export DBHOST=\u0026#34;`echo $CREDS| jq -r \u0026#39;.host\u0026#39;`\u0026#34; export DBPORT=\u0026#34;`echo $CREDS| jq -r \u0026#39;.port\u0026#39;`\u0026#34; echo $DBUSER echo $DBPASS echo $DBHOST echo $DBPORT Una vez conectado a tu instancia de MySQL carga una muestra de datos a tu instancia RDS. Para cargar datos ejecuta este comando desde el cliente de MySQL.  source employees.sql El motor comenzarÃ¡ a cargar los datos y verÃ¡s una salida similar a esta:\nQuery OK, 7671 rows affected (0.05 sec) Records: 7671 Duplicates: 0 Warnings: 0 +---------------------+ | data_load_time_diff | +---------------------+ | 00:00:33 | +---------------------+ 1 row in set (0.00 sec) mysql\u0026gt; Verifica que la tabla de empleados sea correcta ejecutando el checksum:  use employees; checksum table employees; El resultado serÃ¡ una tabla similar a la de abajo. Escribe los valores originales en un archivo para poder compararlos mÃ¡s tarde.\n+---------------------+-----------+ | Table | Checksum | +---------------------+-----------+ | employees.employees | 610052939 | +---------------------+-----------+ 1 row in set (0.24 sec) Sal del cliente de MySQL.  Asegurate de escribir los resultados de checksum original de la tabla de MySQL 5. Avanza al siguiente laboratorio \u0026ldquo;Actualizando la version del motor de MySQL RDS\u0026rdquo;.\n"
},
{
	"uri": "/es/gettingstarted/prereqisites.html",
	"title": "Prerequisitos",
	"tags": [],
	"description": "",
	"content": " En tu ambiente de Cloud9 clona el siguiente repositorio de Git:  git clone https://git-codecommit.us-east-1.amazonaws.com/v1/repos/graviton2-labs cd graviton2-labs Actualiza la AWS CLI de acuerdo a la guia en la documentaciÃ³n AWS documentation.  sudo pip install --upgrade awscli \u0026amp;\u0026amp; hash -r Instala jq, envsubst (de las utilerÃ­as de GNU gettext), tambÃ­en instala bash-completion.  sudo yum -y install jq gettext bash-completion moreutils Instala el cliente de mysql y sus librerias.  sudo yum -y localinstall https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm sudo yum -y install mysql-community-client mysql-community-libs Instala las herramientas necesarias de Kubernetes para interactura con el cluster de EKS.  sudo curl --silent --location -o /usr/local/bin/kubectl \\  https://amazon-eks.s3.us-west-2.amazonaws.com/1.17.11/2020-09-18/bin/linux/amd64/kubectl sudo chmod +x /usr/local/bin/kubectl kubectl completion bash \u0026gt;\u0026gt; ~/.bash_completion . /etc/profile.d/bash_completion.sh . ~/.bash_completion Configura tu cuenta y la region en las variables de ambiente.  export ACCOUNT_ID=$(aws sts get-caller-identity --output text --query Account) export AWS_REGION=$(curl -s 169.254.169.254/latest/dynamic/instance-identity/document | jq -r \u0026#39;.region\u0026#39;) echo \u0026#34;export ACCOUNT_ID=${ACCOUNT_ID}\u0026#34; | tee -a ~/.bash_profile echo \u0026#34;export AWS_REGION=${AWS_REGION}\u0026#34; | tee -a ~/.bash_profile aws configure set default.region ${AWS_REGION} aws configure set default.account ${ACCOUNT_ID} aws configure get default.region aws configure get default.account SSH key  Ejecuta este comando para generar tus llaves SSH en el ambiente de Cloud9. Utilizaremos estas llaves en los worker nodes y nos permitiran tener acceso ssh a las instancias en caso de ser necesario.\nssh-keygen  Presiona enter 3 veces para seleccionar las opciones predeterminadas.\n Sube tu llave publica a tu instancia EC2:\naws ec2 import-key-pair --key-name \u0026#34;graviton2key\u0026#34; --public-key-material file://~/.ssh/id_rsa.pub Si tienes algun error similar a este: An error occurred (InvalidKey.Format) when calling the ImportKeyPair operation: Key is not in valid OpenSSH public key format utiliza este comando para subir tus llaves:\naws ec2 import-key-pair --key-name \u0026#34;graviton2key\u0026#34; --public-key-material fileb://~/.ssh/id_rsa.pub Prepara tu ambiente para usar el servicio AWS CDK:  python3 -m venv .venv source .venv/bin/activate pip install --upgrade aws-cdk.core pip install -r requirements.txt cdk bootstrap aws://$ACCOUNT_ID/$AWS_REGION cdk synth cdk ls "
},
{
	"uri": "/es/amazonrds/02_upgrade/upgradingmysq.html",
	"title": "Actualizando la version del motor de MySQL RDS",
	"tags": [],
	"description": "",
	"content": "Cuando Amazon RDS soporte nuevas versiones de un motor de bases de datos podrÃ¡s comenzar con el proceso de actualizaciÃ³n de instancias de bases de datos. Existen dos tipos de actializaciones para instancias de bases de datos con MySQL: major version upgrades y minor version upgrades.\nMajor version upgrades o actualizaciones de version mayores pueden contener cambios en el motor que no permiten tener retrocompatibilidad con versiones o aplicaciones anteriores. Como resiltando de esto, estos cambios deberan de ejecutarse de forma manual en tus instancias de bases de datos y puedes hacerlos al modificar tu instancia de bases de datos.\nEn este laboratorio te guaremos en los pasos que debes seguir para hacer la actualizacion de tu motor de MySQL para tu instancia de RDS. Estas operaciones se realizaran desde tu ambiente de Cloud9 usando la linea de comando de AWS pero es importante que sepas que tambien puedes realizarlas desde la consola de AWS o realizando llamados al API modify-db-instance.\nTe recomendamos que pruebes cualquier cambio antes de realizarlo en instancias productivas, de modo que puedas entender perfectamente el impacto de cada cambio.\n  Inicia el proceso de actualizaciÃ³n de un major version upgrade process ejecutando el siguiente cÃ³digo en tu ambiente de Cloud9:  aws rds modify-db-instance --db-instance-identifier `aws cloudformation describe-stacks --stack-name GravitonID-rds-5 --query \u0026quot;Stacks[0].Outputs[1].OutputValue\u0026quot; --output text` --engine-version 8.0.21 --allow-major-version-upgrade --apply-immediately Monitorea el proceso de actualizaciÃ³n de tu base de datos desde la Consola de AWS o con el siguiente cÃ³digo:  aws rds describe-db-instances --db-instance-identifier $DBID | jq -r .DBInstances[0].DBInstanceStatus Una vez que el proceso de actualizaciÃ³n finalice y tu base de datos tenga el estado de \u0026ldquo;Availabe\u0026rdquo; conectate a un instancia de MySQL que acabas de actualizar con el siguiente comando:  mysql -h $DBHOST -P $DBPORT -u$DBUSER -p$DBPASS Verifica que la tabla de empleados en Graviton2 sea correcta ejecutando el checksum:  use employees; checksum table employees; El resultado serÃ¡ una tabla similar a la de abajo. Compara estos resultados con el checksum original que escribiste en el capitulo anterior  +---------------------+-----------+ | Table | Checksum | +---------------------+-----------+ | employees.employees | 610052939 | +---------------------+-----------+ 1 row in set (0.24 sec) Sal del cliente de MySQL  "
},
{
	"uri": "/es/amazoncontainers/amazoneks/ekscluster.html",
	"title": "AmazonEKS : CreaciÃ³n de un cluster EKS multi-arquitectura",
	"tags": [],
	"description": "",
	"content": "Amazon Elastic Kubernetes Service (Amazon EKS) es un servicio administrado que puedes utilizar para ejecutar Kubernetes en aws sin necesidad de instalar, operar y mantener tu propio plano de control o nodos de un clÃºster. Kubernetes es un sistema de cÃ³digo abierto para automatizar la implementaciÃ³n, escalabilidad y orquestaciÃ³n de aplicaciones containerizadas.\n Revisa el contenido del stack de CDK localizado en el archivo graviton-labs/graviton2/cs_graviton/eks_graviton2.py. Este stack crearÃ¡ un cluster de EKS con dos nodegroups: un grupo para arquitectura x86 y otro para arquitectura ARM64   self.cluster = eks.Cluster(self, \u0026quot;EKSGraviton2\u0026quot;, version=eks.KubernetesVersion.V1_18, default_capacity=0, endpoint_access=eks.EndpointAccess.PUBLIC_AND_PRIVATE, vpc=vpc, security_group=eks_security_group ) self.ng_x86 = self.cluster.add_nodegroup_capacity(\u0026quot;x86-node-group\u0026quot;, instance_types=[ec2.InstanceType(\u0026quot;m5.large\u0026quot;)], desired_size=2, min_size=1, max_size=3 ) self.ng_arm64 = self.cluster.add_nodegroup_capacity(\u0026quot;arm64-node-group\u0026quot;, instance_types=[ec2.InstanceType(\u0026quot;m6g.large\u0026quot;)], desired_size=2, min_size=1, max_size=3 ) Implementa el cluster de EKS con los dos nodegroups utilizando CDK:  cdk deploy GravitonID-eks  Este proceso puede tardar de 15 a 20 minutos. Es una gran oportunidad de tomarte un descanso.\n Una vez que el cluster y los nodegroups estÃ©n disponibles, ejecuta el siguiente comando para crear el archivo de configuraciÃ³n de kubectl:  `aws cloudformation describe-stacks --stack-name GravitonID-eks --query \u0026#34;Stacks[0].Outputs[1].OutputValue\u0026#34; --output text` Prueba el cluster y verifica los nodos que lo componen:  kubectl get nodes --label-columns=kubernetes.io/arch DeberÃ­as ver una salida similar a la descrita aquÃ­. Cuatro nodos en total, de los cuales 2 utilizan instancias ARM64 basadas en Graviton2 y dos utilizan AMD64.\nNAME STATUS ROLES AGE VERSION ARCH ip-10-0-2-105.ec2.internal Ready \u0026lt;none\u0026gt; 10h v1.18.9-eks-d1db3c amd64 ip-10-0-2-193.ec2.internal Ready \u0026lt;none\u0026gt; 10h v1.18.9-eks-d1db3c arm64 ip-10-0-3-28.ec2.internal Ready \u0026lt;none\u0026gt; 10h v1.18.9-eks-d1db3c arm64 ip-10-0-3-58.ec2.internal Ready \u0026lt;none\u0026gt; 10h v1.18.9-eks-d1db3c amd64 Ahora tienes un cluster de EKS totalmente funcional que puede ejecutar aplicaciones hechas en mÃºltiples arquitecturas.\nContinua al siguiente paso  "
},
{
	"uri": "/es/amazonrds/01_snapshot/restoringrds.html",
	"title": "RecuperaciÃ³n del snapshot de la instancia con Graviton2",
	"tags": [],
	"description": "",
	"content": "Ya estamos listos para hacer la recuperaciÃ³n de la base de datos a una nueva en una instancia con Graviton2. Revisa los contenidos del archivo de definicion de la instancia de bases de datos RDS MySQL 8 que se encuentra en la ruta graviton2_labs/rds_graviton/ds_restore.py\n snapshot_id = ssm.StringParameter.value_for_string_parameter(self ,\u0026quot;graviton_rds_lab_snapshot\u0026quot;) g2_db_mysql8 = rds.DatabaseInstanceFromSnapshot(self, \u0026quot;GravitonMySQL\u0026quot;, engine=rds.DatabaseInstanceEngine.mysql( version=rds.MysqlEngineVersion.VER_8_0_21 ), instance_type=ec2.InstanceType(\u0026quot;m6g.4xlarge\u0026quot;), snapshot_identifier=snapshot_id, vpc=vpc, multi_az=False, publicly_accessible=True, allocated_storage=100, storage_type=rds.StorageType.IO1, iops=5000, cloudwatch_logs_exports=[\u0026quot;error\u0026quot;, \u0026quot;general\u0026quot;, \u0026quot;slowquery\u0026quot;], enable_performance_insights=True, deletion_protection=False, delete_automated_backups=True, backup_retention=core.Duration.days(1), vpc_subnets={ \u0026quot;subnet_type\u0026quot;: ec2.SubnetType.PUBLIC }, parameter_group=rds.ParameterGroup.from_parameter_group_name( self, \u0026quot;para-group-mysql\u0026quot;, parameter_group_name=\u0026quot;default.mysql8.0\u0026quot; ) )  Usaremos el snapshot que creamos de la instancia original con arquitectura x86 para hacer la recuperaciÃ³n en la instancia de Graviton2 nueva. Ejecuta el cÃ³digo siguiente para crear la instancia de Graviton2:  cdk deploy GravitonID-rds-restore Antes de conectarte la instancia de Graviton2 con MySQL actualizaremos el nombre de usuario y contraseÃ±a en las variables de ambiente de la sesiÃ³n de Cloud9.  CREDS=$(aws secretsmanager get-secret-value --secret-id `aws cloudformation describe-stacks --stack-name GravitonID-rds-8 --query \u0026#34;Stacks[0].Outputs[0].OutputValue\u0026#34; --output text` | jq -r \u0026#39;.SecretString\u0026#39;) export DBUSER=\u0026#34;`echo $CREDS| jq -r \u0026#39;.username\u0026#39;`\u0026#34; export DBPASS=\u0026#34;`echo $CREDS| jq -r \u0026#39;.password\u0026#39;`\u0026#34; export DBPORT=\u0026#34;`echo $CREDS| jq -r \u0026#39;.port\u0026#39;`\u0026#34; export DBHOST=$(aws rds describe-db-instances --db-instance-identifier `aws cloudformation describe-stacks --stack-name GravitonID-rds-restore --query \u0026#34;Stacks[0].Outputs[0].OutputValue\u0026#34; --output text` | jq -r \u0026#39;.DBInstances[] | .Endpoint.Address\u0026#39;) echo $DBUSER echo $DBPASS echo $DBHOST echo $DBPORT Es momento de conectarnos a la instancia de MySQL MySQL. Ejecuta el siguiente cÃ³digo en tu instancia:  mysql -h $DBHOST -P $DBPORT -u$DBUSER -p$DBPASS Verifica que la tabla de empleados en la instancia con Graviton2 sea correcta ejecutando el checksum:  use employees; checksum table employees; El resultado serÃ¡ una tabla similar a la de abajo. Compara estos resultados con el checksum original que escribiste en el capitulo anterior\n+---------------------+-----------+ | Table | Checksum | +---------------------+-----------+ | employees.employees | 610052939 | +---------------------+-----------+ 1 row in set (0.24 sec) Sal del cliente de MySQL  Hasta este momento cuentas con una copia funcional de tu base de datos original en Amazon RDS con Graviton2 y tipo de instancia M6g "
},
{
	"uri": "/es/amazoncontainers/amazoneks/k8sapplication.html",
	"title": "AmazonEKS : ImplementaciÃ³n de una aplicaciÃ³n multi-arquitectura",
	"tags": [],
	"description": "",
	"content": "Ahora estamos listos para implementar una aplicaciÃ³n multi-arquitectura sobre kubernetes\n Revisa el contenido del manifiesto de implementaciÃ³n de kubernetes en el archivo: graviton2-labs/graviton2/cs_graviton/Deployment.yaml  apiVersion: apps/v1 kind: Deployment metadata: name: multiarch-deployment namespace: multiarch labels: app: multiarch-app spec: replicas: 4 selector: matchLabels: app: multiarch-app template: metadata: labels: app: multiarch-app spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: beta.kubernetes.io/arch operator: In values: - amd64 - arm64 podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - multiarch-app topologyKey: \u0026#34;kubernetes.io/hostname\u0026#34; containers: - name: multiarch-container image: {{container_uri}} ports: - containerPort: 80 Este manifiesto implementarÃ¡ cuatro pods en todos los nodos de EKS (tanto en los x86 como los ARM64).\nUtiliza el siguiente comando para iniciar la implementaciÃ³n:  cd ~/environment/graviton2-labs CONTAINER_URI=`aws ssm get-parameter --name \u0026#34;graviton_lab_container_uri\u0026#34; | jq -r .Parameter.Value` cat graviton2/cs_graviton/Deployment.yaml | sed \u0026#34;s#{{container_uri}}#$CONTAINER_URI#\u0026#34; | kubectl apply -f - Puedes revisar el estatus de la implementaciÃ³n ejecutando el siguiente comando:  kubectl get svc,deployment -n multiarch Accede a la aplicaciÃ³n multi-arquitectura via el DNS del balanceador de carga:  TomarÃ¡ varios minutos para que el balanceador pase a estatus saludable y comience a enviar trÃ¡fico a los pods\n ELB=$(kubectl get service multiarch-service -n multiarch -o json | jq -r \u0026#39;.status.loadBalancer.ingress[].hostname\u0026#39;) for i in {1..8}; do curl -m3 $ELB ; echo; done  Si lo deseas, puedes copiar y pegar el DNS del balanceador de cargas en tu navegador para ver la aplicaciÃ³n en ejecuciÃ³n.\n Es importante resaltar que estamos utilizando un Ãºnico tag con Amazon ECR y Amazon EKS y esto nos da soporte multi-arquitectura nativo para que la imagen de contenedor adecuada sea seleccionada automÃ¡ticamente para cada nodegroup.\n Felicidades!!! Has implementado una aplicaciÃ³n multi-arquitectura en dos nodegroups utilizando instancias x86 y ARM64 Opcional: Puedes forzar una falla en el escenario al utilizar una imagen de docker de arquitectura Ãºnica en vez de multi-arquitectura. Escala hacia abajo la implementaciÃ³n actual a cero, cambia el tag de la imagen base para que apunte a una de arquitectura Ãºnica y luego escala hacia arriba la implementaicÃ³n. AquÃ­ los comandos:\nkubectl -n multiarch scale deployment multiarch-deployment --replicas=0 kubectl -n multiarch set image deployment/multiarch-deployment multiarch-container=$CONTAINER_URI-x86 kubectl -n multiarch scale deployment multiarch-deployment --replicas=4 DespuÃ©s de que la implementaciÃ³n se estabilice, ejecuta el siguiente comando para revisar el estatus:\nkubectl get pod -n multiarch DeberÃ­as poder ver algo similar a lo mostrado aquÃ­, en donde solo dos pods se reportan como \u0026ldquo;Running\u0026rdquo; (en ejecuciÃ³n) y otros dos muestran un estatus \u0026ldquo;CrashLoopBackOff\u0026rdquo; o \u0026ldquo;Error\u0026rdquo;.\nNAME READY STATUS RESTARTS AGE multiarch-deployment-857dbcdd7c-5455t 0/1 CrashLoopBackOff 6 9m33s multiarch-deployment-857dbcdd7c-l48zd 1/1 Running 0 9m33s multiarch-deployment-857dbcdd7c-ptf65 1/1 Running 0 9m33s multiarch-deployment-857dbcdd7c-xk8vh 0/1 CrashLoopBackOff 6 9m33s "
},
{
	"uri": "/es/amazonrds/02_upgrade/modyfyinginstancetype.html",
	"title": "Cambiando el tipo de instancia a Graviton2",
	"tags": [],
	"description": "",
	"content": "Puedes cambiar la configuraciÃ³n de la instancia de la base de datos y agregar almacenamiento adicional o cambiar el tipo de la instancia. Esto incluye cambiar de una instancia con arquitectura x86 a un tipo de instancia con Graviton2 y arquitectura arm.\nTe recomendamos que pruebes cualquier cambio en instancias de prueba antes de hacer cambios a una productiva de manera que entiendas perfectamente el impacto de cualquier cambio. Como se menciona en el capitulo anterior, realizar estas pruebas es importante cuando se actualizan versiones del motor de bases de datos.\nLa mayoria de las modificaciones a una instancia de bases de datos pueden aplicar inmediatamente o pueden ser aplicadas en la siguiente ventana de mantenimiento y podrÃ¡s hacer la que sea mÃ¡s conveniente para tÃ­.\n Inicia el proceso de cambiar el tipo de la instancia ejecutando el siguiente cÃ³digo en tu ambiente de Cloud9:   aws rds modify-db-instance --db-instance-identifier `aws cloudformation describe-stacks --stack-name GravitonID-rds-5 --query \u0026quot;Stacks[0].Outputs[1].OutputValue\u0026quot; --output text` --db-instance-class db.m6g.4xlarge --allow-major-version-upgrade --apply-immediately Monitorea el proceso de actualizaciÃ³n de tu base de datos desde la Consola de AWS o con el siguiente cÃ³digo:  aws rds describe-db-instances --db-instance-identifier $DBID | jq -r .DBInstances[0].DBInstanceStatus Una vez que el proceso de actualizaciÃ³n finalice y tu base de datos tenga el estado de \u0026ldquo;Availabe\u0026rdquo; conectate a un instancia de MySQL que acabas de actualizar con el siguiente comando:  mysql -h $DBHOST -P $DBPORT -u$DBUSER -p$DBPASS Verifica que la tabla de empleados en Graviton2 sea correcta ejecutando el checksum:  use employees; checksum table employees; El resultado serÃ¡ una tabla similar a la de abajo. Compara estos resultados con el checksum original que escribiste en el capitulo anterior  +---------------------+-----------+ | Table | Checksum | +---------------------+-----------+ | employees.employees | 610052939 | +---------------------+-----------+ 1 row in set (0.24 sec) Sal del cliente de MySQL  Consulta la documentaciÃ³n https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.DBInstance.Modifying.html para obtener mÃ¡s detalles sobre la modificaciÃ³n de instancias de bases de datos en RDS.\n"
},
{
	"uri": "/es/amazonrds/01_snapshot.html",
	"title": "OpciÃ³n 1: Restaurar una base de datos Graviton2 con MySQL en RDS a partir de un snapshot x86",
	"tags": [],
	"description": "",
	"content": "En este capitulo, restauraras una instancia Graviton2 MySQL RDS a partir de un snapshot tomado de una instancia RDS MySQL con arquitectura x86.\n"
},
{
	"uri": "/es/amazonemr/cleanup.html",
	"title": "Limpieza del laboratorio de EMR",
	"tags": [],
	"description": "",
	"content": "Para limpiar el laboratorio de EMR por favor ejecute el siguiente comando, el cual eliminarÃ¡ el clÃºster y los nodos que lo componen:\naws emr terminate-clusters --cluster-ids $EMR_CLUSTER_ID DespuÃ©s de revisar el contenido en el bucket de S3 puedes elegir el borrar la salida del job o el bucket completo utilizando la consola web o la lÃ­nea de comando.\n"
},
{
	"uri": "/es/amazoncontainers/amazoneks/aspnet.html",
	"title": "AmazonEKS : Ejecutando aplicaciones hechas en ASP.NET Core sobre Graviton2",
	"tags": [],
	"description": "",
	"content": "Una de las grandes fortalezas de la plataforma .NET Core es que .NET 5 tiene mejoras significativas en rendimiento y estÃ¡ listo para esfuerzos de modernizaciÃ³n escalables. Los clientes pueden tambiÃ©n elegir construir sus aplicaciones hechas en .NET Core utilizando el procesador AWS Graviton2. AWS es el Ãºnico proveedor de nube que ofrece la opciÃ³n de ejecutar cargas de trabajo en .NET sobre arquitecturas ARM64 Las instncias EC2 que son ejecutadas con AWS Graviton2 proveen hasta un 40% en mejora de precio/rendimiento sobre generaciones actuales de instancias basadas en x86. Los procesadores Graviton2 ayudan a los clientes a darse cuenta de la mejora significativa de rendimiento de sus aplicaciones creadas en .NET sobre distribuciones soportadas de linux (Alpine Linux, Debian, and Ubuntu).\nAsegÃºrate de haber completado el laboratorio \u0026ldquo;AmazonEKS : CreaciÃ³n de un cluster EKS multi-arquitectura\u0026rdquo; antes de iniciar este.\n Inicia revisando el stack de CDK responsable por implementar el pipeline de construcciÃ³n de .NET Core en el archivo: graviton2-labs/graviton2/cs_graviton/pipeline_netcore_graviton2.py .\n docker_build_arm64 = codebuild.PipelineProject( scope=self, id=f\u0026quot;DockerBuild_ARM64\u0026quot;, environment=dict( build_image=codebuild.LinuxBuildImage.AMAZON_LINUX_2_ARM, privileged=True), environment_variables={ 'REPO_ECR': codebuild.BuildEnvironmentVariable( value=container_repository.repository_uri), }, build_spec=buildspec_arm64 )   Implementa el pipeline utilizando CDK:  cd ~/environment/graviton2-labs/ cdk deploy GravitonID-pipeline-dotnet Clona el repositorio ejemplo de .NET de git:  git clone https://github.com/dotnet/dotnet-docker.git Clona el repositorio de .NET Core de CodeCommit:  git clone `aws cloudformation describe-stacks --stack-name GravitonID-pipeline-dotnet --query \u0026#34;Stacks[0].Outputs[0].OutputValue\u0026#34; --output text` Copia los archivos de especificaciÃ³n de code build y la aplicaciÃ³n ejemplo de .NET Core 5 al nuevo repositorio git:  cp -r dotnet-docker/samples/aspnetapp/* graviton2-aspnet-lab/ cp dotnet-docker/samples/aspnetapp/Dockerfile.debian-arm64 graviton2-aspnet-lab/Dockerfile cp graviton2/cs_graviton/arm64-dotnet-buildspec.yml graviton2-aspnet-lab/ Ejecuta los comandos siguientes para hacer commit y subir los cambios al repositorio de CodeCommit:  cd ~/environment/graviton2-labs/graviton2-aspnet-lab/ git add . git commit -m \u0026#34;.Net Core 5 ASP Net Sample First Commit\u0026#34; git push Esto inicializarÃ¡\n la construcciÃ³n de la imagen de docker basada en .NET Core 5 y arquitectura ARM64 SubirÃ¡ la imagen de docker al repositorio de ECR.   Monitorea los pasos del pipeline en CodePipeline utilizando la consola de AWS. Puedes ir directo a esta vista dando clic en la siguiente liga: https://console.aws.amazon.com/codesuite/codepipeline/pipelines/graviton2-pipeline-lab/view?region=us-east-1\n  Cuando todos los pasos del pipeline en CodePipeline hayan sido marcados como exitosos, regresa al ambiente de Cloud9 y ejecuta lo siguientes comandos para configurar las variables de ambiente para la implementaciÃ³n\n  export NET_REPO_URI=$(aws ecr describe-repositories --repository-name graviton2-aspnet-lab | jq -r \u0026#39;.repositories[0].repositoryUri\u0026#39;) export NET_IMAGE_TAG=$(aws ecr describe-images --repository-name graviton2-aspnet-lab --query \u0026#39;sort_by(imageDetails,\u0026amp; imagePushedAt)[-1].imageTags[0]\u0026#39; | jq -r .) export NET_CONTAINER_URI=$NET_REPO_URI:$NET_IMAGE_TAG echo $NET_REPO_URI echo $NET_IMAGE_TAG echo $NET_CONTAINER_URI aws ssm put-parameter --name \u0026#34;graviton_net_container_uri\u0026#34; --value $NET_CONTAINER_URI --type String --overwrite Implementa la aplicaciÃ³n hecha en .NET Core 5 en el cluster de EKS  cd ~/environment/graviton2-labs/ cat graviton2/cs_graviton/Deployment-aspnet.yaml | sed \u0026#34;s#{{container_uri}}#$NET_CONTAINER_URI#\u0026#34; | kubectl apply -f - Puedes revisar el estatus de tu implementaciÃ³n ejecutando:  kubectl get svc,deployment,po -n aspnet Accede a la aplicaciÃ³n utilizando el DNS del Balanceador de carga (ELB)  TomarÃ¡ varios minutos para que el balanceador de carga pase a estatus \u0026ldquo;saludable\u0026rdquo; y comience a enviarle trÃ¡fico a los pods.\n NET_ELB=$(kubectl get service aspnet-service -n aspnet -o json | jq -r \u0026#39;.status.loadBalancer.ingress[].hostname\u0026#39;) echo $NET_ELB Copia y pega el nombre de DNS del balanceador de carga en tu navegador. DeberÃ¡s poder ver la aplicaciÃ³n en ejecuciÃ³n.\nFelicidades!!! Implementaste una aplicaciÃ³n hecha en .NET Core usando Amazon EKS + instancias Graviton2. "
},
{
	"uri": "/es/amazonrds/02_upgrade.html",
	"title": "OpciÃ³n 2 : Actualizar la versiÃ³n de MySQL RDS",
	"tags": [],
	"description": "",
	"content": "En este capitulo empezaremos por hacer el upgrade de MySQL 5 en la instancia RDS a una versiÃ³n mÃ¡s reciente de MySQL para despues modificar el tipo de la instancia a una con Graviton2.\nEstas modificaciones usualmente se calendarizan para que ocurran durante la siguiente ventana de mantenimiento para minimizar las interrupciones del servicio.\n"
},
{
	"uri": "/es/amazonrds.html",
	"title": "Graviton2 y Bases de Datos",
	"tags": [],
	"description": "",
	"content": "Graviton2 brinda mejoras costo-rendimiento en tus Bases de Datos Relacionales del servicio de Amazon RDS comparado con las generaciones anteriores de tipos de instancia M5 y R5 con la utilizando de los nuevos procesadores AWS Graviton2 en RDS.\nEn esta seccion exploraremos el servicio de Amazon Relational Database Service (RDS) con el nuevo procesador Graviton2. Aunque nos enfocaremos en bases de datos MySQL, este proceso es aplicable para otras motores de bases de datos (MySQL 8.0.17+, MariaDB 10.4.13+, y tambien a PostgreSQL 12.3+ son soportados para el uso de RDS con Gravtion2. Cuando seleccionemos tipos de instancia para RDS podras elegir entre la familia de instancias M6g y R6g.\n Las instancias M6g son ideas para cargas de trabajo de propositos generales. Las instancias R6g ofrecen 50% mÃ¡s memoria que las M6g y son ideales para cargas de trabajo que requieran de memoria intensiva, como por ejemplo, analiticos y big data.  Podras explorar los dos caminos existentes para migrar tus bases de datos de codigo abierto existentes a tipos de instancias con procesador Graviton2:\nOpciÃ³n 1) Crear una nueva base de datos con una versiÃ³n compatible de motor de vases de datos a partir de un snapshot (recomendado para ambientes productivos)\nOpciÃ³n 2) Actualizar tu motor de bases de datos a una versiÃ³n soportada por RDS con Graviton2, modificando el tipo de instancia de forma sencilla (ambientes de desarrollo/pruebas)\n"
},
{
	"uri": "/es/amazoncontainers.html",
	"title": "Graviton2 y Contenedores",
	"tags": [],
	"description": "",
	"content": "En este capÃ­tulo exploraremos cÃ³mo ejecutar contenedores utilizando soporte nativo a mÃºltiples arquitecturas (ARM y/o x86) en Amazon EKS, Amazon ECR y herramientas de AWS para desarrolladores como lo son AWS CodeBuild, CodeDeploy y CodePipeline.\n"
},
{
	"uri": "/es/amazonemr.html",
	"title": "Graviton2 y Big Data",
	"tags": [],
	"description": "",
	"content": "En este capÃ­tulo exploraremos la ejecuciÃ³n de un cluster de Amazon EMR en instancias Graviton2. EMR soporta nativamente instancias Graviton2, asÃ­ que en este escenario nos enfocaremos en ejecutar un job de Spark.\n"
},
{
	"uri": "/es/amazoncontainers/amazonecs/ecscluster.html",
	"title": "AmazonECS : Implementando un cluster de ECS con instancias Graviton2",
	"tags": [],
	"description": "",
	"content": "Amazon Elastic Container Service (Amazon ECS) es un servicio de manejo de contenedores altamente escalable y rÃ¡pido que hace sencilla la ejecuciÃ³n, escalabilidad y el manejo de contenedores en un cluster. Tus contenedores estÃ¡n definidos en una \u0026ldquo;definiciÃ³n de tarea\u0026rdquo; que utilizarÃ¡s para ejecutar \u0026ldquo;tareas\u0026rdquo; individuales o \u0026ldquo;tareas\u0026rdquo; como parte de un \u0026ldquo;servicio\u0026rdquo;. Amazon ECS te permite inicializar y detener tus aplicaciones basadas en contenedires utilizando llamadas de API muy simples. AdemÃ¡s, puedes conocer el estado de tu cluster desde un servicio centralizado y tienes acceso a muchas caracterÃ­sticas de Amazon EC2 y VPC.\nAsegÃºrate de completar el laboratorio \u0026ldquo;ConstrucciÃ³n multi-arquitectura de la aplicaciÃ³n\u0026rdquo; antes de iniciar esta secciÃ³n.\n Comienza revisando el contenido de la \u0026ldquo;definiciÃ³n de tarea\u0026rdquo; en el archivo: graviton2-labs/graviton2/cs_graviton/ecs_graviton2.py\necs_ami = ecs.EcsOptimizedAmi(generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2, hardware_type=ecs.AmiHardwareType.ARM) asg_ecs = cluster.add_capacity(\u0026#34;G2AutoScalingGroup\u0026#34;, instance_type=ec2.InstanceType(\u0026#34;m6g.2xlarge\u0026#34;), machine_image=ecs_ami ) container = task_definition.add_container( \u0026#34;web\u0026#34;, image=ecs.ContainerImage.from_registry(\u0026#34;{{container_uri}}\u0026#34;), memory_limit_mib=512, logging=ecs.LogDrivers.firelens( options={ \u0026#34;Name\u0026#34;: \u0026#34;cloudwatch\u0026#34;, \u0026#34;log_key\u0026#34;: \u0026#34;log\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;delivery_stream\u0026#34;: \u0026#34;my-stream\u0026#34;, \u0026#34;log_group_name\u0026#34;: \u0026#34;firelens-fluent-bit\u0026#34;, \u0026#34;auto_create_group\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;log_stream_prefix\u0026#34;: \u0026#34;from-fluent-bit\u0026#34;} ) )  Crea el cluster de ECS utilizando Amazon CDK  cdk deploy GravitonID-ecs Una vez el cluster y la \u0026ldquo;tarea\u0026rdquo; en Amazon ECS se encuentre disponible, ejecuta los siguientes comandos para verificar el endpoint de DNS del balanceador de carga asociado (Amazon ELB).  TomarÃ¡ varios minutos para que el balanceador de carga pase a estatus \u0026ldquo;saludable\u0026rdquo; y comience a enviarle trÃ¡fico a las \u0026ldquo;tareas\u0026rdquo;.\n ECS_ELB=$(aws cloudformation describe-stacks --stack-name GravitonID-ecs --query \u0026#34;Stacks[0].Outputs[0].OutputValue\u0026#34; --output text) Prueba el clÃºster y verifica que tu servicio estÃ© utilizando una instancia Graviton2.  for i in {1..8}; do curl -m3 $ECS_ELB ; echo; done Ahora tienes un cluster de ECS funcionando con instancias Graviton2!\n"
},
{
	"uri": "/es/amazoncontainers/cleanup.html",
	"title": "Graviton2 y contenedores: Limpieza",
	"tags": [],
	"description": "",
	"content": "Ejecuta los siguientes comandos para limpliar el ambiente de trabajo.\ncd ~/environment/graviton2-labs/ scripts/cs_cleanup.sh "
},
{
	"uri": "/es/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/es/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]